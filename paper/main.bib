@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@article{tolman1948cognitive,
  title={Cognitive maps in rats and men.},
  author={Tolman, Edward C},
  journal={Psychological review},
  volume={55},
  number={4},
  pages={189},
  year={1948},
  publisher={American Psychological Association}
}

@article{shepard1988mental,
  title={Mental rotation: effects of dimensionality of objects and type of task.},
  author={Shepard, Shenna and Metzler, Douglas},
  journal={Journal of experimental psychology: Human perception and performance},
  volume={14},
  number={1},
  pages={3},
  year={1988},
  publisher={American Psychological Association}
}

@book{newcombe2000making,
  title={Making space: The development of spatial representation and reasoning},
  author={Newcombe, Nora and Huttenlocher, Janellen},
  year={2000},
  publisher={MIT press}
}

@article{kuipers1978modeling,
  title={Modeling spatial knowledge},
  author={Kuipers, Benjamin},
  journal={Cognitive science},
  volume={2},
  number={2},
  pages={129--153},
  year={1978},
  publisher={Elsevier}
}

@article{kuipers2000spatial,
  title={The spatial semantic hierarchy},
  author={Kuipers, Benjamin},
  journal={Artificial intelligence},
  volume={119},
  number={1-2},
  pages={191--233},
  year={2000},
  publisher={Elsevier}
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

@article{durrant2006simultaneous,
  title={Simultaneous localization and mapping: part I},
  author={Durrant-Whyte, Hugh and Bailey, Tim},
  journal={IEEE robotics \& automation magazine},
  volume={13},
  number={2},
  pages={99--110},
  year={2006},
  publisher={IEEE}
}

@article{thrun2002probabilistic,
  title={Probabilistic robotics},
  author={Thrun, Sebastian},
  journal={Communications of the ACM},
  volume={45},
  number={3},
  pages={52--57},
  year={2002},
  publisher={ACM New York, NY, USA}
}

@article{hong20233d,
  title={3d-llm: Injecting the 3d world into large language models},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={20482--20494},
  year={2023}
}

@article{bai2023qwen,
  title={Qwen technical report},
  author={Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and others},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  year={2020}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{openai-gpt-3.5,
  title = {OpenAI API Documentation},
  author = {OpenAI},
  year = {2023},
  howpublished = {\url{https://platform.openai.com/docs/models/gpt-3-5}},
  note = {Accessed on September 19, 2025}
}
@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@misc{seed2025seed-oss,
  author={ByteDance Seed Team},
  title={Seed-OSS Open-Source Models},
  year={2025},
  howpublished={\url{https://github.com/ByteDance-Seed/seed-oss}}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{liu2024deepseek,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{bai2025qwen2,
  title={Qwen2. 5-vl technical report},
  author={Bai, Shuai and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Song, Sibo and Dang, Kai and Wang, Peng and Wang, Shijie and Tang, Jun and others},
  journal={arXiv preprint arXiv:2502.13923},
  year={2025}
}

@article{guo2025seed1,
  title={Seed1. 5-vl technical report},
  author={Guo, Dong and Wu, Faming and Zhu, Feida and Leng, Fuxing and Shi, Guang and Chen, Haobin and Fan, Haoqi and Wang, Jian and Jiang, Jianyu and Wang, Jiawei and others},
  journal={arXiv preprint arXiv:2505.07062},
  year={2025}
}

@article{comanici2025gemini,
  title={Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities},
  author={Comanici, Gheorghe and Bieber, Eric and Schaekermann, Mike and Pasupat, Ice and Sachdeva, Noveen and Dhillon, Inderjit and Blistein, Marcel and Ram, Ori and Zhang, Dan and Rosen, Evan and others},
  journal={arXiv preprint arXiv:2507.06261},
  year={2025}
}

@article{hurst2024gpt,
  title={Gpt-4o system card},
  author={Hurst, Aaron and Lerer, Adam and Goucher, Adam P and Perelman, Adam and Ramesh, Aditya and Clark, Aidan and Ostrow, AJ and Welihinda, Akila and Hayes, Alan and Radford, Alec and others},
  journal={arXiv preprint arXiv:2410.21276},
  year={2024}
}

@article{gur2023real,
  title={A real-world webagent with planning, long context understanding, and program synthesis},
  author={Gur, Izzeddin and Furuta, Hiroki and Huang, Austin and Safdari, Mustafa and Matsuo, Yutaka and Eck, Douglas and Faust, Aleksandra},
  journal={arXiv preprint arXiv:2307.12856},
  year={2023}
}

@article{wang2025ui,
  title={UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning},
  author={Wang, Haoming and Zou, Haoyang and Song, Huatong and Feng, Jiazhan and Fang, Junjie and Lu, Junting and Liu, Longxiang and Luo, Qinyu and Liang, Shihao and Huang, Shijue and others},
  journal={arXiv preprint arXiv:2509.02544},
  year={2025}
}

@book{piaget2013construction,
  title={The construction of reality in the child},
  author={Piaget, Jean},
  year={2013},
  publisher={Routledge}
}

@article{intelligence2025pi_,
    title={\(\backslash\pi\_ \{0.5\}\): a Vision-Language-Action Model with Open-World Generalization},
    author={Intelligence, Physical and Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and others},
    journal={arXiv preprint arXiv:2504.16054},
    year={2025}
}

@article{genie3,
  title         = {Genie 3: A New Frontier for World Models},
  author        = {Philip J. Ball and Jakob Bauer and Frank Belletti and Bethanie Brownfield and Ariel Ephrat and Shlomi Fruchter and Agrim Gupta and Kristian Holsheimer and Aleksander Holynski and Jiri Hron and Christos Kaplanis and Marjorie Limont and Matt McGill and Yanko Oliveira and Jack Parker-Holder and Frank Perbet and Guy Scully and Jeremy Shar and Stephen Spencer and Omer Tov and Ruben Villegas and Emma Wang and Jessica Yung and Cip Baetu and Jordi Berbel and David Bridson and Jake Bruce and Gavin Buttimore and Sarah Chakera and Bilva Chandra and Paul Collins and Alex Cullum and Bogdan Damoc and Vibha Dasagi and Maxime Gazeau and Charles Gbadamosi and Woohyun Han and Ed Hirst and Ashyana Kachra and Lucie Kerley and Kristian Kjems and Eva Knoepfel and Vika Koriakin and Jessica Lo and Cong Lu and Zeb Mehring and Alex Moufarek and Henna Nandwani and Valeria Oliveira and Fabio Pardo and Jane Park and Andrew Pierson and Ben Poole and Helen Ran and Tim Salimans and Manuel Sanchez and Igor Saprykin and Amy Shen and Sailesh Sidhwani and Duncan Smith and Joe Stanton and Hamish Tomlinson and Dimple Vijaykumar and Luyu Wang and Piers Wingfield and Nat Wong and Keyang Xu and Christopher Yew and Nick Young and Vadim Zubov and Douglas Eck and Dumitru Erhan and Koray Kavukcuoglu and Demis Hassabis and Zoubin Gharamani and Raia Hadsell and A{\"a}ron van den Oord and Inbar Mosseri and Adrian Bolton and Satinder Singh and Tim Rockt{\"a}schel},
  year          = {2025},
  url           = {}
}

@article{UI-TARS,
  author       = {Yujia Qin and
                  Yining Ye and
                  Junjie Fang and
                  Haoming Wang and
                  Shihao Liang and
                  Shizuo Tian and
                  Junda Zhang and
                  Jiahao Li and
                  Yunxin Li and
                  Shijue Huang and
                  Wanjun Zhong and
                  Kuanye Li and
                  Jiale Yang and
                  Yu Miao and
                  Woyu Lin and
                  Longxiang Liu and
                  Xu Jiang and
                  Qianli Ma and
                  Jingyu Li and
                  Xiaojun Xiao and
                  Kai Cai and
                  Chuang Li and
                  Yaowei Zheng and
                  Chaolin Jin and
                  Chen Li and
                  Xiao Zhou and
                  Minchao Wang and
                  Haoli Chen and
                  Zhaojian Li and
                  Haihua Yang and
                  Haifeng Liu and
                  Feng Lin and
                  Tao Peng and
                  Xin Liu and
                  Guang Shi},
  title        = {{UI-TARS:} Pioneering Automated {GUI} Interaction with Native Agents},
  journal      = {CoRR},
  volume       = {abs/2501.12326},
  year         = {2025},
}

@inproceedings{xu2024pointllm,
  title={Pointllm: Empowering large language models to understand point clouds},
  author={Xu, Runsen and Wang, Xiaolong and Wang, Tai and Chen, Yilun and Pang, Jiangmiao and Lin, Dahua},
  booktitle={European Conference on Computer Vision},
  pages={131--147},
  year={2024},
  organization={Springer}
}

@inproceedings{yang2025thinking,
  title={Thinking in space: How multimodal large language models see, remember, and recall spaces},
  author={Yang, Jihan and Yang, Shusheng and Gupta, Anjali W and Han, Rilyn and Fei-Fei, Li and Xie, Saining},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={10632--10643},
  year={2025}
}

@article{ma20243dsrbench,
  title={3dsrbench: A comprehensive 3d spatial reasoning benchmark},
  author={Ma, Wufei and Chen, Haoyu and Zhang, Guofeng and Chou, Yu-Cheng and de Melo, Celso M and Yuille, Alan},
  journal={arXiv preprint arXiv:2412.07825},
  year={2024}
}

@inproceedings{wang2024spatial,
        title={Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models},
        author={Wang, Jiayu and Ming, Yifei and Shi, Zhenmei and Vineet, Vibhav and Wang, Xin and Li, Yixuan and Joshi, Neel},
        booktitle={The Thirty-Eighth Annual Conference on Neural Information Processing Systems},
        year={2024}
}

@article{zhu2024llava,
  title={Llava-3d: A simple yet effective pathway to empowering lmms with 3d-awareness},
  author={Zhu, Chenming and Wang, Tai and Zhang, Wenwei and Pang, Jiangmiao and Liu, Xihui},
  journal={arXiv preprint arXiv:2409.18125},
  year={2024}
}

@inproceedings{fu2024blink,
  title={Blink: Multimodal large language models can see but not perceive},
  author={Fu, Xingyu and Hu, Yushi and Li, Bangzheng and Feng, Yu and Wang, Haoyu and Lin, Xudong and Roth, Dan and Smith, Noah A and Ma, Wei-Chiu and Krishna, Ranjay},
  booktitle={European Conference on Computer Vision},
  pages={148--166},
  year={2024},
  organization={Springer}
}

@article{wang2025site,
  title={SITE: towards Spatial Intelligence Thorough Evaluation},
  author={Wang, Wenqi and Tan, Reuben and Zhu, Pengyue and Yang, Jianwei and Yang, Zhengyuan and Wang, Lijuan and Kolobov, Andrey and Gao, Jianfeng and Gong, Boqing},
  journal={arXiv preprint arXiv:2505.05456},
  year={2025}
}

@article{wang2025spatialviz,
  title={Spatialviz-bench: Automatically generated spatial visualization reasoning tasks for mllms},
  author={Wang, Siting and Sun, Luoyang and Deng, Cheng and Shao, Kun and Pei, Minnan and Tian, Zheng and Zhang, Haifeng and Wang, Jun},
  journal={arXiv preprint arXiv:2507.07610},
  year={2025}
}

@article{gholami2025spatial,
  title={Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes},
  author={Gholami, Mohsen and Rezaei, Ahmad and Weimin, Zhou and Zhang, Yong and Akbari, Mohammad},
  journal={arXiv preprint arXiv:2509.06266},
  year={2025}
}

@article{yang2025mmsi,
  title={MMSI-Bench: A Benchmark for Multi-Image Spatial Intelligence},
  author={Yang, Sihan and Xu, Runsen and Xie, Yiman and Yang, Sizhe and Li, Mo and Lin, Jingli and Zhu, Chenming and Chen, Xiaochen and Duan, Haodong and Yue, Xiangyu and others},
  journal={arXiv preprint arXiv:2505.23764},
  year={2025}
}

@article{jia2025omnispatial,
  title={OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models},
  author={Jia, Mengdi and Qi, Zekun and Zhang, Shaochen and Zhang, Wenyao and Yu, Xinqiang and He, Jiawei and Wang, He and Yi, Li},
  journal={arXiv preprint arXiv:2506.03135},
  year={2025}
}

@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@article{ju2024miradata,
  title={Miradata: A large-scale video dataset with long durations and structured captions},
  author={Ju, Xuan and Gao, Yiming and Zhang, Zhaoyang and Yuan, Ziyang and Wang, Xintao and Zeng, Ailing and Xiong, Yu and Xu, Qiang and Shan, Ying},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={48955--48970},
  year={2024}
}

@article{qiu2025humanoid,
  title={Humanoid Policy\~{} Human Policy},
  author={Qiu, Ri-Zhao and Yang, Shiqi and Cheng, Xuxin and Chawla, Chaitanya and Li, Jialong and He, Tairan and Yan, Ge and Yoon, David J and Hoque, Ryan and Paulsen, Lars and others},
  journal={arXiv preprint arXiv:2503.13441},
  year={2025}
}

@article{lin2025towards,
  title={Towards Understanding Camera Motions in Any Video},
  author={Lin, Zhiqiu and Cen, Siyuan and Jiang, Daniel and Karhade, Jay and Wang, Hewei and Mitra, Chancharik and Ling, Tiffany and Huang, Yuhan and Liu, Sifan and Chen, Mingyu and others},
  journal={arXiv preprint arXiv:2504.15376},
  year={2025}
}

@article{yin2025spatial,
  title={Spatial Mental Modeling from Limited Views},
  author={Yin, Baiqiao and Wang, Qineng and Zhang, Pingyue and Zhang, Jianshu and Wang, Kangrui and Wang, Zihan and Zhang, Jieyu and Chandrasegaran, Keshigeyan and Liu, Han and Krishna, Ranjay and others},
  journal={arXiv preprint arXiv:2506.21458},
  year={2025}
}

@article{xu2025multi,
  title={Multi-spatialmllm: Multi-frame spatial understanding with multi-modal large language models},
  author={Xu, Runsen and Wang, Weiyao and Tang, Hao and Chen, Xingyu and Wang, Xiaodong and Chu, Fu-Jen and Lin, Dahua and Feiszli, Matt and Liang, Kevin J},
  journal={arXiv preprint arXiv:2505.17015},
  year={2025}
}

@article{liu2025ir3d,
  title={IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering},
  author={Liu, Parker and Li, Chenxin and Li, Zhengxin and Wu, Yipeng and Li, Wuyang and Yang, Zhiqin and Zhang, Zhenyuan and Lin, Yunlong and Han, Sirui and Feng, Brandon Y},
  journal={arXiv preprint arXiv:2506.23329},
  year={2025}
}

@article{li2024llava_next_interleave,
  title={Llava-next-interleave: Tackling multi-image, video, and 3d in large multimodal models},
  author={Li, Feng and Zhang, Renrui and Zhang, Hao and Zhang, Yuanhan and Li, Bo and Li, Wei and Ma, Zejun and Li, Chunyuan},
  journal={arXiv preprint arXiv:2407.07895},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@misc{openai2023gpt4v,
  author = {OpenAI},
  title = {GPT-4V(ision) System Card},
  year = {2023},
  url = {https://cdn.openai.com/papers/GPTV_System_Card.pdf},
  note = {Accessed: 2025-09-19}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={34892--34916},
  year={2023}
}

@article{yume,
  author       = {Xiaofeng Mao and
                  Shaoheng Lin and
                  Zhen Li and
                  Chuanhao Li and
                  Wenshuo Peng and
                  Tong He and
                  Jiangmiao Pang and
                  Mingmin Chi and
                  Yu Qiao and
                  Kaipeng Zhang},
  title        = {Yume: An Interactive World Generation Model},
  journal      = {CoRR},
  volume       = {abs/2507.17744},
  year         = {2025},
}

@article{wang2025pi,
  title={\(\backslash\pi^3\): Scalable Permutation-Equivariant Visual Geometry Learning},
  author={Wang, Yifan and Zhou, Jianjun and Zhu, Haoyi and Chang, Wenzheng and Zhou, Yang and Li, Zizun and Chen, Junyi and Pang, Jiangmiao and Shen, Chunhua and He, Tong},
  journal={arXiv preprint arXiv:2507.13347},
  year={2025}
}

@inproceedings{wang2025vggt,
  title={Vggt: Visual geometry grounded transformer},
  author={Wang, Jianyuan and Chen, Minghao and Karaev, Nikita and Vedaldi, Andrea and Rupprecht, Christian and Novotny, David},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={5294--5306},
  year={2025}
}

@inproceedings{xiao2024spatialtracker,
  title={Spatialtracker: Tracking any 2d pixels in 3d space},
  author={Xiao, Yuxi and Wang, Qianqian and Zhang, Shangzhan and Xue, Nan and Peng, Sida and Shen, Yujun and Zhou, Xiaowei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20406--20417},
  year={2024}
}

@article{xiao2025spatialtrackerv2,
  title={Spatialtrackerv2: 3d point tracking made easy},
  author={Xiao, Yuxi and Wang, Jianyuan and Xue, Nan and Karaev, Nikita and Makarov, Yuri and Kang, Bingyi and Zhu, Xing and Bao, Hujun and Shen, Yujun and Zhou, Xiaowei},
  journal={arXiv preprint arXiv:2507.12462},
  year={2025}
}

@inproceedings{veicht2024geocalib,
  title={Geocalib: Learning single-image calibration with geometric optimization},
  author={Veicht, Alexander and Sarlin, Paul-Edouard and Lindenberger, Philipp and Pollefeys, Marc},
  booktitle={European Conference on Computer Vision},
  pages={1--20},
  year={2024},
  organization={Springer}
}

@inproceedings{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10371--10381},
  year={2024}
}

@misc{wang2025moge2,
      title={MoGe-2: Accurate Monocular Geometry with Metric Scale and Sharp Details}, 
      author={Ruicheng Wang and Sicheng Xu and Yue Dong and Yu Deng and Jianfeng Xiang and Zelong Lv and Guangzhong Sun and Xin Tong and Jiaolong Yang},
      year={2025},
      eprint={2507.02546},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2507.02546}, 
}

@inproceedings{leroy2024grounding,
  title={Grounding image matching in 3d with mast3r},
  author={Leroy, Vincent and Cabon, Yohann and Revaud, J{\'e}r{\^o}me},
  booktitle={European Conference on Computer Vision},
  pages={71--91},
  year={2024},
  organization={Springer}
}

@inproceedings{xiangli2025doppelgangers++,
  title={Doppelgangers++: Improved Visual Disambiguation with Geometric 3D Features},
  author={Xiangli, Yuanbo and Cai, Ruojin and Chen, Hanyu and Byrne, Jeffrey and Snavely, Noah},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={27166--27175},
  year={2025}
}

@article{orient_anything,
  title={Orient Anything: Learning Robust Object Orientation Estimation from Rendering 3D Models},
  author={Wang, Zehan and Zhang, Ziang and Pang, Tianyu and Du, Chao and Zhao, Hengshuang and Zhao, Zhou},
  journal={arXiv:2412.18605},
  year={2024}
}

@article{mao2025spatiallm,
  title={SpatialLM: Training Large Language Models for Structured Indoor Modeling},
  author={Mao, Yongsen and Zhong, Junhao and Fang, Chuan and Zheng, Jia and Tang, Rui and Zhu, Hao and Tan, Ping and Zhou, Zihan},
  journal={arXiv preprint arXiv:2506.07491},
  year={2025}
}

@article{yang2025embodiedbench,
  title={Embodiedbench: Comprehensive benchmarking multi-modal large language models for vision-driven embodied agents},
  author={Yang, Rui and Chen, Hanyang and Zhang, Junyu and Zhao, Mark and Qian, Cheng and Wang, Kangrui and Wang, Qineng and Koripella, Teja Venkat and Movahedi, Marziyeh and Li, Manling and others},
  journal={arXiv preprint arXiv:2502.09560},
  year={2025}
}

@misc{egodex,
      title={EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video}, 
      author={Ryan Hoque and Peide Huang and David J. Yoon and Mouli Sivapurapu and Jian Zhang},
      year={2025},
      eprint={2505.11709},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2505.11709}, 
}

@inproceedings{wang2020tartanair,
  title={Tartanair: A dataset to push the limits of visual slam},
  author={Wang, Wenshan and Zhu, Delong and Wang, Xiangwei and Hu, Yaoyu and Qiu, Yuheng and Wang, Chen and Hu, Yafei and Kapoor, Ashish and Scherer, Sebastian},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4909--4916},
  year={2020},
  organization={IEEE}
}

@inproceedings{reizenstein21co3d,
	Author = {Reizenstein, Jeremy and Shapovalov, Roman and Henzler, Philipp and Sbordone, Luca and Labatut, Patrick and Novotny, David},
	Booktitle = {International Conference on Computer Vision},
	Title = {Common Objects in 3D: Large-Scale Learning and Evaluation of Real-life 3D Category Reconstruction},
	Year = {2021},
}
@article{team2025kimi,
  title={Kimi-vl technical report},
  author={Team, Kimi and Du, Angang and Yin, Bohong and Xing, Bowei and Qu, Bowen and Wang, Bowen and Chen, Cheng and Zhang, Chenlin and Du, Chenzhuang and Wei, Chu and others},
  journal={arXiv preprint arXiv:2504.07491},
  year={2025}
}

@article{hong2025glm,
  title={Glm-4.1 v-thinking: Towards versatile multimodal reasoning with scalable reinforcement learning},
  author={Hong, Wenyi and Yu, Wenmeng and Gu, Xiaotao and Wang, Guo and Gan, Guobing and Tang, Haomiao and Cheng, Jiale and Qi, Ji and Ji, Junhui and Pan, Lihang and others},
  journal={arXiv e-prints},
  pages={arXiv--2507},
  year={2025}
}

@misc{openai_gpt5,
  title        = {GPT-5 System Card},
  author       = {{OpenAI}},
  howpublished = {\url{https://openai.com/index/gpt-5-system-card/}},
  year         = {2025},
  note         = {Accessed: 2025-09-25}
}

@misc{anthropic_claude3,
  title        = {Claude 3.7},
  author       = {{Anthropic}},
  howpublished = {\url{https://www.anthropic.com/}},
  year         = {2025},
  note         = {Accessed: 2025-09-25}
}

@article{yang2025qwen3,
  title={Qwen3 technical report},
  author={Yang, An and Li, Anfeng and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Gao, Chang and Huang, Chengen and Lv, Chenxu and others},
  journal={arXiv preprint arXiv:2505.09388},
  year={2025}
}

@article{li2024llava_onevision,
  title={Llava-onevision: Easy visual task transfer},
  author={Li, Bo and Zhang, Yuanhan and Guo, Dong and Zhang, Renrui and Li, Feng and Zhang, Hao and Zhang, Kaichen and Zhang, Peiyuan and Li, Yanwei and Liu, Ziwei and others},
  journal={arXiv preprint arXiv:2408.03326},
  year={2024}
}

@misc{liu2023llava,
      title={Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
      publisher={NeurIPS},
      year={2023},
}

@misc{zhang2024llavanext-video,
  title={LLaVA-NeXT: A Strong Zero-shot Video Understanding Model},
  url={https://llava-vl.github.io/blog/2024-04-30-llava-next-video/},
  author={Zhang, Yuanhan and Li, Bo and Liu, haotian and Lee, Yong jae and Gui, Liangke and Fu, Di and Feng, Jiashi and Liu, Ziwei and Li, Chunyuan},
  month={April},
  year={2024}
}

@article{vst_yang2025,
  title={Visual Spatial Tuning},
  author={Rui Yang and Ziyu Zhu and Yanwei Li and Jingjia Huang and Shen Yan and Siyuan Zhou and Zhe Liu and Xiangtai Li and Shuangye Li and Wenqian Wang and Yi Lin and Hengshuang Zhao},
  journal={arXiv preprint arXiv:2511.05491},
  year={2025}
}

@inproceedings{song2015sun,
  title={Sun rgb-d: A rgb-d scene understanding benchmark suite},
  author={Song, Shuran and Lichtenberg, Samuel P and Xiao, Jianxiong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={567--576},
  year={2015}
}

@inproceedings{Hypersim,
  author       = {Mike Roberts and
                  Jason Ramapuram and
                  Anurag Ranjan and
                  Atulit Kumar and
                  Miguel {\'{A}}ngel Bautista and
                  Nathan Paczan and
                  Russ Webb and
                  Joshua M. Susskind},
  title        = {Hypersim: {A} Photorealistic Synthetic Dataset for Holistic Indoor
                  Scene Understanding},
  booktitle    = {2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
                  2021, Montreal, QC, Canada, October 10-17, 2021},
  publisher    = {{IEEE}},
  year         = {2021},
}

@article{Matterport3D,
  title={Matterport3D: Learning from RGB-D Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  journal={International Conference on 3D Vision (3DV)},
  year={2017}
}

@article{baruch2021arkitscenes,
  title={Arkitscenes: A diverse real-world dataset for 3d indoor scene understanding using mobile rgb-d data},
  author={Baruch, Gilad and Chen, Zhuoyuan and Dehghan, Afshin and Dimry, Tal and Feigin, Yuri and Fu, Peter and Gebauer, Thomas and Joffe, Brandon and Kurz, Daniel and Schwartz, Arik and others},
  journal={arXiv preprint arXiv:2111.08897},
  year={2021}
}